---
title: "ShortProject"
output: pdf_document
date: "2025-06-23"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

As I have told you at our first session, I really want to help people or planet through things that I can do. I believe that technology is a tool for solving global problems and improving the world. 

One of my initiative is an affordable and convenient alternative to traditional electric wheelchairs made by combining a mechanical wheelchair with a gyroscooter(hoverboard) and lever systems. This innovation improves lifes of people with disabilities. Also I researched the accessibility of the environment and its effect on the quality of life of disabled people. I decided my short project to be meaningful and important to me, so I found a data set on kaggle which has different characteristics of vehicles and the column of their wheelchair accessibility  

In this file, I will utilize all my current knowledge of R to get the most information out of this and be able to predict the accessibility ranking from predictors. 

```{r}
library(dplyr)
library(caret)
rm(list=ls())
gc()
mem.maxVSize()
```
Using these, I deleted previous variables and other stuff that I had from other files because there was no enough space for the new data set. 

```{r}
vehicles = read.csv("~/Downloads/algoritmika/python pro 1 year/Дасаева София PP/Learning_R/Stanford/ShortProject/Vehicles.csv", na = c("", "NA"))
dim(vehicles)
```

This is how many rows and columns the data set has. I decided to see how many of NA are there and what to do with them. 

```{r}

dim(vehicles[is.na(vehicles$Vehicle.Type),])
dim(vehicles[is.na(vehicles$Public.Vehicle.Number),])
dim(vehicles[is.na(vehicles$Status),])
dim(vehicles[is.na(vehicles$Vehicle.Make),])
dim(vehicles[is.na(vehicles$Vehicle.Model),])
dim(vehicles[is.na(vehicles$Vehicle.Model.Year),])
dim(vehicles[is.na(vehicles$Vehicle.Color),])
dim(vehicles[is.na(vehicles$Vehicle.Fuel.Source),])
dim(vehicles[is.na(vehicles$Wheelchair.Accessible),])
dim(vehicles[is.na(vehicles$Company.Name),])
dim(vehicles[is.na(vehicles$Address),])
dim(vehicles[is.na(vehicles$City),])
dim(vehicles[is.na(vehicles$State),])
dim(vehicles[is.na(vehicles$ZIP.Code),])
dim(vehicles[is.na(vehicles$Taxi.Affiliation),])
dim(vehicles[is.na(vehicles$Taxi.Medallion.License.Management),])
dim(vehicles[is.na(vehicles$Record.ID),])
dim(vehicles[is.na(vehicles$Last.Valid.Date),])
dim(vehicles[is.na(vehicles$Record.Version.ID),])



```
Vehicle.Make has 3286 NAs (out of 99153) - less than 3%
Vehicle.Model 
Vehicle.Model.Year 
Vehicle.Color
Address
City
State
ZIP.Code
Taxi.Medallion.License.Management
Taxi.Affiliation

```{r}
vehicles <- vehicles[ , -(15:16)]
```
columns like: 
Taxi.Medallion.License.Management
Taxi.Affiliation
have a lot of NAs (34k and 40k), so  we can omit those columns entirely - 30%-40% of them are NAs


```{r}
na_counts <- rowSums(is.na(vehicles))
rows_4plus <- which(na_counts >= 4)
length(rows_4plus)   

vehicles <- vehicles[-rows_4plus, ]
```
Then I also tried to find those rows that doesn't possess a lot of information. For example, those rows that have 4+ NAs when only 8 columns might have NA, don't have in fact a lot of valuable information. So we can delete those. It is 3444 rows.  

There are still columns with NA's, but the number of those NA's decreased significantly. 

```{r}
dim(vehicles[is.na(vehicles$Vehicle.Make),])
dim(vehicles[is.na(vehicles$Vehicle.Model),])
dim(vehicles[is.na(vehicles$Vehicle.Model.Year),])
dim(vehicles[is.na(vehicles$Vehicle.Color),])
dim(vehicles[is.na(vehicles$Address),])
dim(vehicles[is.na(vehicles$City),])
dim(vehicles[is.na(vehicles$State),])
dim(vehicles[is.na(vehicles$ZIP.Code),])
```
Address, City and State don't even have NAs anymore. It means that all those NA's were actually rows with 4+ missing values. The number of those that still have missing value is too small. The biggest of them is just 0.29%. We can delete those too so they don't create noise. Together, I will delete 0.82% of data which is not even a 1%. 

```{r}
na_counts <- rowSums(is.na(vehicles))
rows_1plus <- which(na_counts >= 1)
length(rows_1plus)   

vehicles <- vehicles[-rows_1plus, ]
```

```{r}
dim(vehicles[is.na(vehicles$Vehicle.Make),])
dim(vehicles[is.na(vehicles$Vehicle.Model),])
dim(vehicles[is.na(vehicles$Vehicle.Model.Year),])
dim(vehicles[is.na(vehicles$Vehicle.Color),])
dim(vehicles[is.na(vehicles$ZIP.Code),])
```
There are no missing values now, therefore, we can make a good analysis. 

```{r}
summary(vehicles$Vehicle.Model.Year)
```

The next thing I noticed is that Vehicle.Model.Year contains years like 0 and 2911. 

```{r}
dim(vehicles[(vehicles$Vehicle.Model.Year < 1885),])
dim(vehicles[(vehicles$Vehicle.Model.Year > 2025),])

```
It turned out that 198 rows have not appropriate years. It is about 0.2% of the data, so we can also drop them. 

```{r}
bad <- which(
  vehicles$Vehicle.Model.Year < 1885 |
  vehicles$Vehicle.Model.Year > as.integer(format(Sys.Date(), "%Y"))
)

length(bad)

vehicles <- vehicles[-bad, ]
```
If we ran the summary again, there will be nothing odd:
```{r}
summary(vehicles$Vehicle.Model.Year)

```
Let's dive into real analysis after cleaning the data. 

I decided to take just 80 percent of all the rows as train test and at the same time 20% of rows will be in test. I wanted to save the percantage of wheelchair accessible vehicles over all vehicles. 

As Wheelchair.Accessible is a categorical value, linear regression is not the tool. I will try to use all models that are good at suprevised and supervised learning. Then I will compare which method was the most efficient one for this data set. 

```{r}
lines <- createDataPartition(vehicles$Wheelchair.Accessible, p = 0.8,
                                  list = FALSE,                            
                                  times = 1)

vehicles.train = vehicles[lines, ]
vehicles.test = vehicles[-lines, ]

vehicles.glm = glm(Wheelchair.Accessible ~ ., data = vehicles.train)
```



```{r}
library(dplyr)

range(vehicles$Vehicle.Model.Year, na.rm = TRUE)

attach(vehicles)

vehicles$ModelYear_clean <-
  with(vehicles,
       ifelse(Vehicle.Model.Year < 1900 |
              Vehicle.Model.Year > as.integer(format(Sys.Date(), "%Y")),
              2014, Vehicle.Model.Year)
   )

summary(vehicles$ModelYear_clean)
```

I detected that Years in the data set vary from 0 to 2901 which is bad. I wanted to make those NA's but find out that it will be the whole 3531 values out of 99153. That's why I decided that I can fill those with median value (2014).


set.seed(1)
idx <- createDataPartition(
  y     = vehicles$Wheelchair.Accessible,
  p     = 0.005,       
  list  = FALSE
)

start <- which(names(vehicles) == "City")
end   <- which(names(vehicles) == "State")

vehicles_sample <- vehicles[idx, -(start:end)]

prop.table(table(vehicles$Wheelchair.Accessible))
prop.table(table(vehicles_sample$Wheelchair.Accessible))

contrasts(factor(vehicles_sample$Wheelchair.Accessible))

head(vehicles_sample$Wheelchair.Accessible)

vehicles_sample$AccessibleNum <- ifelse(vehicles_sample$Wheelchair.Accessible == "Y", 1, 0)


summary(glm(AccessibleNum ~ ., 
               data   = vehicles_sample,
               family = binomial,
               na.action = na.omit))

```{r}
library(lubridate)

vehicles$LastValidDate <- mdy_hms(vehicles$Last.Valid.Date, tz="UTC")

range(vehicles$LastValidDate, na.rm = TRUE)
table(year(vehicles$LastValidDate))
```

We can understand from the summary above that Company Name or Model is not really give a statistically significant predictor. Therefore, we can now try glm without it. 

```{r}
vehicles$AccessibleNumber <- ifelse(vehicles$Wheelchair.Accessible == "Y", 1, 0)

summary(glm(AccessibleNumber ~ Status + Vehicle.Fuel.Source + ModelYear_clean + LastValidDate, 
               data   = vehicles,
               family = binomial,
               na.action = na.omit))
```
In the new glm model I used all the rows from the original Vehicle.csv. Now we see that StatusFORECLOSURE, StatusHOLD and ModelYear_clean are significant predictors because their z value and Pr(>|z|) are small enough. From this we can construct our prediction. 


```{r}
train <- subset(vehicles, LastValidDate <= as.POSIXct("2022-12-31 23:59:59", tz="UTC"))
test  <- subset(vehicles, LastValidDate >= as.POSIXct("2023-01-01 00:00:00", tz="UTC"))

accessibility <- vehicles$Wheelchair.Accessible[
  vehicles$LastValidDate >= as.POSIXct("2023-01-01 00:00:00", tz="UTC")
]

```

I created the train set and the test sets of the vehicles data set and also created the accessibility so then we could compare the accuracy. 

```{r}
model = glm(AccessibleNumber ~ Status + ModelYear_clean, data = vehicles, family=binomial)
model.probs = predict(model, test, type="response")

summary(model.probs)

model.preds = rep("N", 2791)
model.preds[model.probs > 0.5] = "Y"

table(model.preds, accessibility)
mean(model.preds == accessibility)

```
we can see that our model only predicts that every vehicle of this type won't be accessible. However, it's accuracy is 99%. If we change the model.probs > 0.5 condition so it would be like "when it is bigger than the mean", it's accuracy will fell down to only 69% 

```{r}

ggplot(data = vehicles) + 
  geom_point(mapping = aes(x = Wheelchair.Accessible, y = ModelYear_clean, color = Vehicle.Fuel.Source))
```


