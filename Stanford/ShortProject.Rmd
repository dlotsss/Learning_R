---
title: "ShortProject"
output: pdf_document
date: "2025-06-23"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

As I have told you at our first session, I really want to help people or planet through things that I can do. I believe that technology is a tool for solving global problems and improving the world. 

One of my initiative is an affordable and convenient alternative to traditional electric wheelchairs made by combining a mechanical wheelchair with a gyroscooter(hoverboard) and lever systems. This innovation improves lifes of people with disabilities. Also I researched the accessibility of the environment and its effect on the quality of life of disabled people. I decided my short project to be meaningful and important to me, so I found a data set on kaggle which has different characteristics of vehicles and the column of their wheelchair accessibility  

In this file, I will utilize all my current knowledge of R to get the most information out of this and be able to predict the accessibility ranking from predictors. 

```{r}

library(caret)
rm(list=ls())
gc()
mem.maxVSize()
```
i deleted previous variables and other stuff because there was no enough space for the new model. 

```{r}
vehicles = read.csv("~/Downloads/Vehicles.csv")
dim(vehicles)
```

this is how namy rows and columns and still not enough space. That's why I decided to take just a little percent of all the rows so R could process them. 

```{r}
library(dplyr)

range(vehicles$Vehicle.Model.Year, na.rm = TRUE)

attach(vehicles)

vehicles$ModelYear_clean <-
  with(vehicles,
       ifelse(Vehicle.Model.Year < 1900 |
              Vehicle.Model.Year > as.integer(format(Sys.Date(), "%Y")),
              2014, Vehicle.Model.Year)
   )

summary(vehicles$ModelYear_clean)
```

I detected that Years in the data set vary from 0 to 2901 which is bad. I wanted to make those NA's but find out that it will be the whole 3531 values out of 99153. That's why I decided that I can fill those with median value (2014).


set.seed(1)
idx <- createDataPartition(
  y     = vehicles$Wheelchair.Accessible,
  p     = 0.005,       
  list  = FALSE
)

start <- which(names(vehicles) == "City")
end   <- which(names(vehicles) == "State")

vehicles_sample <- vehicles[idx, -(start:end)]

prop.table(table(vehicles$Wheelchair.Accessible))
prop.table(table(vehicles_sample$Wheelchair.Accessible))

contrasts(factor(vehicles_sample$Wheelchair.Accessible))

head(vehicles_sample$Wheelchair.Accessible)

vehicles_sample$AccessibleNum <- ifelse(vehicles_sample$Wheelchair.Accessible == "Y", 1, 0)


summary(glm(AccessibleNum ~ ., 
               data   = vehicles_sample,
               family = binomial,
               na.action = na.omit))

```{r}
library(lubridate)

vehicles$LastValidDate <- mdy_hms(vehicles$Last.Valid.Date, tz="UTC")

range(vehicles$LastValidDate, na.rm = TRUE)
table(year(vehicles$LastValidDate))
```

We can understand from the summary above that Company Name or Model is not really give a statistically significant predictor. Therefore, we can now try glm without it. 

```{r}
vehicles$AccessibleNumber <- ifelse(vehicles$Wheelchair.Accessible == "Y", 1, 0)

summary(glm(AccessibleNumber ~ Status + Vehicle.Fuel.Source + ModelYear_clean + LastValidDate, 
               data   = vehicles,
               family = binomial,
               na.action = na.omit))
```
In the new glm model I used all the rows from the original Vehicle.csv. Now we see that StatusFORECLOSURE, StatusHOLD and ModelYear_clean are significant predictors because their z value and Pr(>|z|) are small enough. From this we can construct our prediction. 


```{r}
train <- subset(vehicles, LastValidDate <= as.POSIXct("2022-12-31 23:59:59", tz="UTC"))
test  <- subset(vehicles, LastValidDate >= as.POSIXct("2023-01-01 00:00:00", tz="UTC"))

accessibility <- vehicles$Wheelchair.Accessible[
  vehicles$LastValidDate >= as.POSIXct("2023-01-01 00:00:00", tz="UTC")
]

```

I created the train set and the test sets of the vehicles data set and also created the accessibility so then we could compare the accuracy. 

```{r}
model = glm(AccessibleNumber ~ Status + ModelYear_clean, data = vehicles, family=binomial)
model.probs = predict(model, test, type="response")

summary(model.probs)

model.preds = rep("N", 2791)
model.preds[model.probs > 0.5] = "Y"

table(model.preds, accessibility)
mean(model.preds == accessibility)

```
we can see that our model only predicts that every vehicle of this type won't be accessible. However, it's accuracy is 99%. If we change the model.probs > 0.5 condition so it would be like "when it is bigger than the mean", it's accuracy will fell down to only 69% 

```{r}
library(class)
train.X <- vehicles[vehicles$LastValidDate <= as.POSIXct("2022-12-31 23:59:59", tz="UTC"), c("Status", "ModelYear_clean")]
test.X  <- vehicles[vehicles$LastValidDate >= as.POSIXct("2023-01-01 00:00:00", tz="UTC"),  c("Status", "ModelYear_clean")]
train.Accessibility <- vehicles$Wheelchair.Accessible[vehicles$LastValidDate <= as.POSIXct("2022-12-31 23:59:59", tz="UTC")]

neighbours = c()
accuracy = c()

for (i in 1:50) {
  knn.pred = knn(train.X, test.X, train.Accessibility, k=i)
  accuracy[i] = mean(knn.pred == accessibility)
  neighbours[i] = i
}

plot(neighbours, accuracy)
```


