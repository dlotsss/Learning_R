---
title: "ShortProject"
output: pdf_document
date: "2025-06-23"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

As I have told you at our first session, I really want to help people or planet through things that I can do. I believe that technology is a tool for solving global problems and improving the world. 

One of my initiative is an affordable and convenient alternative to traditional electric wheelchairs made by combining a mechanical wheelchair with a gyroscooter(hoverboard) and lever systems. This innovation improves lifes of people with disabilities. Also I researched the accessibility of the environment and its effect on the quality of life of disabled people. I decided my short project to be meaningful and important to me, so I found a data set on kaggle which has different characteristics of vehicles and the column of their wheelchair accessibility  

In this file, I will utilize all my current knowledge of R to get the most information out of this and be able to predict the accessibility ranking from predictors. 

```{r}
library(dplyr)
library(caret)
rm(list=ls())
gc()
mem.maxVSize()
```
Using these, I deleted previous variables and other stuff that I had from other files because there was no enough space for the new data set. 

```{r}
vehicles = read.csv("~/Downloads/algoritmika/python pro 1 year/Дасаева София PP/Learning_R/Stanford/ShortProject/Vehicles.csv", na = c("", "NA"))
dim(vehicles)
```

This is how many rows and columns the data set has. I decided to see how many of NA are there and what to do with them. 

```{r}

dim(vehicles[is.na(vehicles$Vehicle.Type),])
dim(vehicles[is.na(vehicles$Public.Vehicle.Number),])
dim(vehicles[is.na(vehicles$Status),])
dim(vehicles[is.na(vehicles$Vehicle.Make),])
dim(vehicles[is.na(vehicles$Vehicle.Model),])
dim(vehicles[is.na(vehicles$Vehicle.Model.Year),])
dim(vehicles[is.na(vehicles$Vehicle.Color),])
dim(vehicles[is.na(vehicles$Vehicle.Fuel.Source),])
dim(vehicles[is.na(vehicles$Wheelchair.Accessible),])
dim(vehicles[is.na(vehicles$Company.Name),])
dim(vehicles[is.na(vehicles$Address),])
dim(vehicles[is.na(vehicles$City),])
dim(vehicles[is.na(vehicles$State),])
dim(vehicles[is.na(vehicles$ZIP.Code),])
dim(vehicles[is.na(vehicles$Taxi.Affiliation),])
dim(vehicles[is.na(vehicles$Taxi.Medallion.License.Management),])
dim(vehicles[is.na(vehicles$Record.ID),])
dim(vehicles[is.na(vehicles$Last.Valid.Date),])
dim(vehicles[is.na(vehicles$Record.Version.ID),])



```
Vehicle.Make has 3286 NAs (out of 99153) - less than 3%
Vehicle.Model 
Vehicle.Model.Year 
Vehicle.Color
Address
City
State
ZIP.Code
Taxi.Medallion.License.Management
Taxi.Affiliation

```{r}
vehicles <- vehicles[ , -(15:16)]
```
columns like: 
Taxi.Medallion.License.Management
Taxi.Affiliation
have a lot of NAs (34k and 40k), so  we can omit those columns entirely - 30%-40% of them are NAs


```{r}
na_counts <- rowSums(is.na(vehicles))
rows_4plus <- which(na_counts >= 4)
length(rows_4plus)   

vehicles <- vehicles[-rows_4plus, ]
```
Then I also tried to find those rows that doesn't possess a lot of information. For example, those rows that have 4+ NAs when only 8 columns might have NA, don't have in fact a lot of valuable information. So we can delete those. It is 3444 rows.  

There are still columns with NA's, but the number of those NA's decreased significantly. 

```{r}
dim(vehicles[is.na(vehicles$Vehicle.Make),])
dim(vehicles[is.na(vehicles$Vehicle.Model),])
dim(vehicles[is.na(vehicles$Vehicle.Model.Year),])
dim(vehicles[is.na(vehicles$Vehicle.Color),])
dim(vehicles[is.na(vehicles$Address),])
dim(vehicles[is.na(vehicles$City),])
dim(vehicles[is.na(vehicles$State),])
dim(vehicles[is.na(vehicles$ZIP.Code),])
```
Address, City and State don't even have NAs anymore. It means that all those NA's were actually rows with 4+ missing values. The number of those that still have missing value is too small. The biggest of them is just 0.29%. We can delete those too so they don't create noise. Together, I will delete 0.82% of data which is not even a 1%. 

```{r}
na_counts <- rowSums(is.na(vehicles))
rows_1plus <- which(na_counts >= 1)
length(rows_1plus)   

vehicles <- vehicles[-rows_1plus, ]
```

```{r}
dim(vehicles[is.na(vehicles$Vehicle.Make),])
dim(vehicles[is.na(vehicles$Vehicle.Model),])
dim(vehicles[is.na(vehicles$Vehicle.Model.Year),])
dim(vehicles[is.na(vehicles$Vehicle.Color),])
dim(vehicles[is.na(vehicles$ZIP.Code),])
```
There are no missing values now, therefore, we can make a good analysis. 

```{r}
summary(vehicles$Vehicle.Model.Year)
```

The next thing I noticed is that Vehicle.Model.Year contains years like 0 and 2911. 

```{r}
dim(vehicles[(vehicles$Vehicle.Model.Year < 1885),])
dim(vehicles[(vehicles$Vehicle.Model.Year > 2025),])

```
It turned out that 198 rows have not appropriate years. It is about 0.2% of the data, so we can also drop them. 

```{r}
bad <- which(
  vehicles$Vehicle.Model.Year < 1885 |
  vehicles$Vehicle.Model.Year > as.integer(format(Sys.Date(), "%Y"))
)

length(bad)

vehicles <- vehicles[-bad, ]
```
If we ran the summary again, there will be nothing odd:
```{r}
summary(vehicles$Vehicle.Model.Year)

```
It turned out that State column has only one value - IL, which will not affect the y in any way, so I will drop it. 
```{r}
vehicles = vehicles[, -13]
```
Let's dive into real analysis after cleaning the data. 

I decided to take just 80 percent of all the rows as train test and at the same time 20% of rows will be in test. I wanted to save the percantage of wheelchair accessible vehicles over all vehicles. 

As Wheelchair.Accessible is a categorical value, linear regression is not the tool. I will try to use all models that are good at suprevised and supervised learning. Then I will compare which method was the most efficient one for this data set. 

I tried to iterate the code on different predictors, because it was to much for the model to proccess if do it everything all at once
```{r}
lines <- createDataPartition(vehicles$Wheelchair.Accessible, p = 0.8,
                                  list = FALSE,                            
                                  times = 1)

vehicles$Wheelchair.Accessible<- ifelse(
  vehicles$Wheelchair.Accessible == "Y", 1, 0
)

vehicles.train = vehicles[lines, ]
vehicles.test = vehicles[-lines, ]

vehicles.glm = glm(Wheelchair.Accessible ~ Vehicle.Type, data = vehicles.train, 
                   family = binomial)
summary(vehicles.glm)

```
If type is Charter Sightseeing, Medicar  or Taxi, it has statistically significant effect on the y

```{r}
vehicles.glm = glm(Wheelchair.Accessible ~ Public.Vehicle.Number, data = vehicles.train, 
                   family = binomial)
summary(vehicles.glm)

```
Public.Vehicle.Number is considered statistically important, but it needs to be checked

```{r}
vehicles.glm = glm(Wheelchair.Accessible ~ Status, data = vehicles.train, 
                   family = binomial)
summary(vehicles.glm)

```
If status is FORECLOSURE, INACTIVE, RESERVED, SURRENDER, VIOLATION, it does have a significant effect on the y. 
Status of HOLD is considered moderately significant

```{r}
vehicles.glm = glm(Wheelchair.Accessible ~ Vehicle.Make, data = vehicles.train, 
                   family = binomial)
summary(vehicles.glm)

```
Vehicle.Make doesn't affect the Wheelchair Accessibility

```{r}
vehicles.glm = glm(Wheelchair.Accessible ~ Vehicle.Model, data = vehicles.train, 
                   family = binomial)
summary(vehicles.glm)

```
Vehicle.Model also doesn't affect the Wheelchair Accessibility

```{r}
vehicles.glm = glm(Wheelchair.Accessible ~ Vehicle.Model.Year, data = vehicles.train, 
                   family = binomial)
summary(vehicles.glm)
```
Wheelchair.Model.Year is statistically significant 

```{r}
vehicles.glm = glm(Wheelchair.Accessible ~ Vehicle.Color, data = vehicles.train, 
                   family = binomial)
summary(vehicles.glm)

```
Vehicle.Color is not statistically significant for y

```{r}
vehicles.glm = glm(Wheelchair.Accessible ~ Vehicle.Fuel.Source, data = vehicles.train, 
                   family = binomial)
summary(vehicles.glm)
```
Vehicle.Fuel.Source is also considered not important for the vehicle.  

For the following columns, training data set was too large, therefore, I decided to make a very little data subset just to check whether those predictors are significant or not. 

```{r}
lines <- createDataPartition(vehicles$Wheelchair.Accessible, p = 0.01,
                                  list = FALSE,                            
                                  times = 1)
vehicles.check = vehicles[lines, ]
vehicles.glm = glm(Wheelchair.Accessible ~ Company.Name, data = vehicles.check, 
                  family = binomial)
summary(vehicles.glm)
```
Company.Name is not a significant predictor

```{r}
# find top 10
top10 <- names(sort(table(vehicles.train$Company.Name), decreasing=TRUE))[1:10]

# create a new factor with only 11 levels (10 + “Other”)
vehicles.train$Company2 <- factor(
  ifelse(vehicles.train$Company.Name %in% top10,
         vehicles.train$Company.Name,
         "Other"),
  levels = c(top10, "Other")
)

summary(glm(Wheelchair.Accessible ~ Company2, data = vehicles.train, 
                  family = binomial))
```

```{r}
vehicles.glm = glm(Wheelchair.Accessible ~ Address, data = vehicles.check, 
                   family = binomial)
summary(vehicles.glm)
```
Address is also not a significant predictor

```{r}
vehicles.glm = glm(Wheelchair.Accessible ~ City, data = vehicles.train, 
                   family = binomial)
summary(vehicles.glm)
```


```{r}
vehicles.glm = glm(Wheelchair.Accessible ~ Record.ID, data = vehicles.check, 
                   family = binomial)
summary(vehicles.glm)
```


```{r}
vehicles.glm = glm(Wheelchair.Accessible ~ ZIP.Code, data = vehicles.train, 
                   family = binomial)
summary(vehicles.glm)
```
ZIP code appears to be statistically significant. 

```{r}
vehicles.glm = glm(Wheelchair.Accessible ~ Last.Valid.Date, data = vehicles.check, 
                   family = binomial)
summary(vehicles.glm)
```


```{r}
vehicles.glm = glm(Wheelchair.Accessible ~ Record.Version.ID, data = vehicles.check, 
                   family = binomial)
summary(vehicles.glm)
```







Now, as we undesrtood statistically significant predictors, we can make a real model. 
```{r}
vehicles.glm = glm(Wheelchair.Accessible ~ Vehicle.Type + Status + Vehicle.Model.Year 
                   + Public.Vehicle.Number + ZIP.Code, data = vehicles.train, family = "binomial")

summary(vehicles.glm)
```
From this summary we can understand that Vehicle.Type, Status, Vehicle.Model.Year, Public.Vehicle.Numer and ZIP.Code are indeed statistically significant predictors. 

Now we need to see how accurately the model predicts the outcomes (whether the vehicle will be accessible or not)

We can understand from the summary above that Company Name or Model is not really give a statistically significant predictor. Therefore, we can now try glm without it. 

```{r}
vehicles$AccessibleNumber <- ifelse(vehicles$Wheelchair.Accessible == "Y", 1, 0)

summary(glm(AccessibleNumber ~ Status + Vehicle.Fuel.Source + ModelYear_clean + LastValidDate, 
               data   = vehicles,
               family = binomial))
```
In the new glm model I used all the rows from the original Vehicle.csv. Now we see that StatusFORECLOSURE, StatusHOLD and ModelYear_clean are significant predictors because their z value and Pr(>|z|) are small enough. From this we can construct our prediction. 


```{r}
train <- subset(vehicles, LastValidDate <= as.POSIXct("2022-12-31 23:59:59", tz="UTC"))
test  <- subset(vehicles, LastValidDate >= as.POSIXct("2023-01-01 00:00:00", tz="UTC"))

accessibility <- vehicles$Wheelchair.Accessible[
  vehicles$LastValidDate >= as.POSIXct("2023-01-01 00:00:00", tz="UTC")
]

```

I created the train set and the test sets of the vehicles data set and also created the accessibility so then we could compare the accuracy. 

```{r}
model = glm(AccessibleNumber ~ Status + ModelYear_clean, data = vehicles, family=binomial)
model.probs = predict(model, test, type="response")

summary(model.probs)

model.preds = rep("N", 2791)
model.preds[model.probs > 0.5] = "Y"

table(model.preds, accessibility)
mean(model.preds == accessibility)

```
we can see that our model only predicts that every vehicle of this type won't be accessible. However, it's accuracy is 99%. If we change the model.probs > 0.5 condition so it would be like "when it is bigger than the mean", it's accuracy will fell down to only 69% 

```{r}

ggplot(data = vehicles) + 
  geom_point(mapping = aes(x = Wheelchair.Accessible, y = ModelYear_clean, color = Vehicle.Fuel.Source))
```


