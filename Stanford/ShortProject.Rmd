---
title: "ShortProject"
output: pdf_document
date: "2025-06-23"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

As I have told you at our first session, I really want to help people or planet through things that I can do. I believe that technology is a tool for solving global problems and improving the world. 

One of my initiative is an affordable and convenient alternative to traditional electric wheelchairs made by combining a mechanical wheelchair with a gyroscooter(hoverboard) and lever systems. This innovation improves lifes of people with disabilities. Also I researched the accessibility of the environment and its effect on the quality of life of disabled people. I decided my short project to be meaningful and important to me, so I found a data set on kaggle which has different characteristics of vehicles and the column of their wheelchair accessibility  

In this file, I will utilize all my current knowledge of R to get the most information out of this and be able to predict the accessibility ranking from predictors. 

```{r}
library(dplyr)
library(caret)
rm(list=ls())
gc()
mem.maxVSize()
```
Using these, I deleted previous variables and other stuff that I had from other files because there was no enough space for the new data set. 

```{r}
vehicles = read.csv("~/Downloads/algoritmika/python pro 1 year/Дасаева София PP/Learning_R/Stanford/ShortProject/Vehicles.csv", na = c("", "NA"))
dim(vehicles)
```

This is how many rows and columns the data set has. I decided to see how many of NA are there and what to do with them. 

```{r}

dim(vehicles[is.na(vehicles$Vehicle.Type),])
dim(vehicles[is.na(vehicles$Public.Vehicle.Number),])
dim(vehicles[is.na(vehicles$Status),])
dim(vehicles[is.na(vehicles$Vehicle.Make),])
dim(vehicles[is.na(vehicles$Vehicle.Model),])
dim(vehicles[is.na(vehicles$Vehicle.Model.Year),])
dim(vehicles[is.na(vehicles$Vehicle.Color),])
dim(vehicles[is.na(vehicles$Vehicle.Fuel.Source),])
dim(vehicles[is.na(vehicles$Wheelchair.Accessible),])
dim(vehicles[is.na(vehicles$Company.Name),])
dim(vehicles[is.na(vehicles$Address),])
dim(vehicles[is.na(vehicles$City),])
dim(vehicles[is.na(vehicles$State),])
dim(vehicles[is.na(vehicles$ZIP.Code),])
dim(vehicles[is.na(vehicles$Taxi.Affiliation),])
dim(vehicles[is.na(vehicles$Taxi.Medallion.License.Management),])
dim(vehicles[is.na(vehicles$Record.ID),])
dim(vehicles[is.na(vehicles$Last.Valid.Date),])
dim(vehicles[is.na(vehicles$Record.Version.ID),])



```
Vehicle.Make has 3286 NAs (out of 99153) - less than 3%
Vehicle.Model 
Vehicle.Model.Year 
Vehicle.Color
Address
City
State
ZIP.Code
Taxi.Medallion.License.Management
Taxi.Affiliation

```{r}
vehicles <- vehicles[ , -(15:16)]
```
columns like: 
Taxi.Medallion.License.Management
Taxi.Affiliation
have a lot of NAs (34k and 40k), so  we can omit those columns entirely - 30%-40% of them are NAs


```{r}
na_counts <- rowSums(is.na(vehicles))
rows_4plus <- which(na_counts >= 4)
length(rows_4plus)   

vehicles <- vehicles[-rows_4plus, ]
```
Then I also tried to find those rows that doesn't possess a lot of information. For example, those rows that have 4+ NAs when only 8 columns might have NA, don't have in fact a lot of valuable information. So we can delete those. It is 3444 rows.  

There are still columns with NA's, but the number of those NA's decreased significantly. 

```{r}
dim(vehicles[is.na(vehicles$Vehicle.Make),])
dim(vehicles[is.na(vehicles$Vehicle.Model),])
dim(vehicles[is.na(vehicles$Vehicle.Model.Year),])
dim(vehicles[is.na(vehicles$Vehicle.Color),])
dim(vehicles[is.na(vehicles$Address),])
dim(vehicles[is.na(vehicles$City),])
dim(vehicles[is.na(vehicles$State),])
dim(vehicles[is.na(vehicles$ZIP.Code),])
```
Address, City and State don't even have NAs anymore. It means that all those NA's were actually rows with 4+ missing values. The number of those that still have missing value is too small. The biggest of them is just 0.29%. We can delete those too so they don't create noise. Together, I will delete 0.82% of data which is not even a 1%. 

```{r}
na_counts <- rowSums(is.na(vehicles))
rows_1plus <- which(na_counts >= 1)
length(rows_1plus)   

vehicles <- vehicles[-rows_1plus, ]
```

```{r}
dim(vehicles[is.na(vehicles$Vehicle.Make),])
dim(vehicles[is.na(vehicles$Vehicle.Model),])
dim(vehicles[is.na(vehicles$Vehicle.Model.Year),])
dim(vehicles[is.na(vehicles$Vehicle.Color),])
dim(vehicles[is.na(vehicles$ZIP.Code),])
```
There are no missing values now, therefore, we can make a good analysis. 

```{r}
summary(vehicles$Vehicle.Model.Year)
```

The next thing I noticed is that Vehicle.Model.Year contains years like 0 and 2911. 

```{r}
dim(vehicles[(vehicles$Vehicle.Model.Year < 1885),])
dim(vehicles[(vehicles$Vehicle.Model.Year > 2025),])

```
It turned out that 198 rows have not appropriate years. It is about 0.2% of the data, so we can also drop them. 

```{r}
bad <- which(
  vehicles$Vehicle.Model.Year < 1885 |
  vehicles$Vehicle.Model.Year > as.integer(format(Sys.Date(), "%Y"))
)

length(bad)

vehicles <- vehicles[-bad, ]
```
If we ran the summary again, there will be nothing odd:
```{r}
summary(vehicles$Vehicle.Model.Year)

```
It turned out that State column has only one value - IL, which will not affect the y in any way, so I will drop it. 
```{r}
vehicles = vehicles[, -13]
```
Next, there are a lot of company names, however they are repeated. Same with records, records.versions and dates
```{r}
companies <- names(sort(table(vehicles$Company.Name), decreasing=TRUE))

records <- names(sort(table(vehicles$Record.ID), decreasing=TRUE))
records.versions <- names(sort(table(vehicles$Record.Version.ID), decreasing=TRUE))
dates <- names(sort(table(vehicles$Last.Valid.Date), decreasing=TRUE))

adresses <- names(sort(table(vehicles$Address), decreasing=TRUE))

```
There are 10591 unique names of companies. GLM will not be able to divide all of those names into separate predictors, therefore we need a new categorical value about companies. I will divide it into groups like top1000, top2000, top3000....

13445 unique of records
8131 unique of dates
4260 unique of addresses

```{r}
companies <- sort(table(vehicles$Company.Name), decreasing = TRUE)
company_levels <- names(companies)
ranks <- seq_along(company_levels)
rank_lookup <- setNames(ranks, company_levels)

breaks <- c(0, seq(1000, 10000, by = 1000), Inf)
labels <- c(paste0("Top ", seq(1000, 10000, by = 1000)), "Other")

vehicles$CompanyGroup <- sapply(vehicles$Company.Name, function(x) {
  r <- rank_lookup[x]
  if (is.na(r)) return("Other")
  bucket <- findInterval(r, vec = breaks, rightmost.closed = TRUE)
  labels[bucket]
})

vehicles$CompanyGroup <- factor(
  vehicles$CompanyGroup,
  levels = labels
)

table(vehicles$CompanyGroup)
```
Now there are only 11 variables which will be easier to process for the model. This means that those most frequent 1000 companies are grouped at Top1000, then Top2000 and etc

Same thing I will do for Record.ID
```{r}
records <- sort(table(vehicles$Record.ID), decreasing = TRUE)
record_levels <- names(records)
ranks <- seq_along(record_levels)
rank_lookup <- setNames(ranks, record_levels)

breaks <- c(0, seq(1000, 13000, by = 1000), Inf)
labels <- c(paste0("Top ", seq(1000, 13000, by = 1000)), "Other")

vehicles$RecordsGroup <- sapply(vehicles$Record.ID, function(x) {
  r <- rank_lookup[x]
  if (is.na(r)) return("Other")
  bucket <- findInterval(r, vec = breaks, rightmost.closed = TRUE)
  labels[bucket]
})

vehicles$RecordsGroup <- factor(
  vehicles$RecordsGroup,
  levels = labels
)

table(vehicles$RecordsGroup)
```
And the same thing for Last.Valid.Date 

```{r}
dates <- sort(table(vehicles$Last.Valid.Date), decreasing = TRUE)
dates_levels <- names(dates)
ranks <- seq_along(dates_levels)
rank_lookup <- setNames(ranks, dates_levels)

breaks <- c(0, seq(1000, 8000, by = 1000), Inf)
labels <- c(paste0("Top ", seq(1000, 8000, by = 1000)), "Other")

vehicles$DatesGroup <- sapply(vehicles$Last.Valid.Date, function(x) {
  r <- rank_lookup[x]
  if (is.na(r)) return("Other")
  bucket <- findInterval(r, vec = breaks, rightmost.closed = TRUE)
  labels[bucket]
})

vehicles$DatesGroup <- factor(
    vehicles$DatesGroup,
  levels = labels
)

table(vehicles$DatesGroup)
```
And same for Addresses

```{r}
addresses <- sort(table(vehicles$Address), decreasing = TRUE)
addresses_levels <- names(addresses)
ranks <- seq_along(addresses_levels)
rank_lookup <- setNames(ranks, addresses_levels)

breaks <- c(0, seq(1000, 4000, by = 1000), Inf)
labels <- c(paste0("Top ", seq(1000, 4000, by = 1000)), "Other")

vehicles$AddressesGroup <- sapply(vehicles$Address, function(x) {
  r <- rank_lookup[x]
  if (is.na(r)) return("Other")
  bucket <- findInterval(r, vec = breaks, rightmost.closed = TRUE)
  labels[bucket]
})

vehicles$AddressesGroup <- factor(
    vehicles$AddressesGroup,
  levels = labels
)

table(vehicles$AddressesGroup)
```

After we have Group columns we don't really need those original columns, so we can drop those. At the same time Records.Versions variable is unique for each row, so it will not give us valuable information in classification. Probably, it is connected to the Records.ID column. We can drop it, too. 
```{r}
vehicles = vehicles[, -(10:11)]
vehicles = vehicles[, -(12:14)]
```


Let's dive into real analysis after cleaning the data. 

I decided to take just 80 percent of all the rows as train test and at the same time 20% of rows will be in test. I wanted to save the percantage of wheelchair accessible vehicles over all vehicles. 

As Wheelchair.Accessible is a categorical value, linear regression is not the tool. I will try to use all models that are good at suprevised and supervised learning. Then I will compare which method was the most efficient one for this data set. 

I tried to iterate the code on different predictors, because it was to much for the model to proccess if do it everything all at once
```{r}
set.seed(1)
lines <- createDataPartition(vehicles$Wheelchair.Accessible, p = 0.8,
                                  list = FALSE,                            
                                  times = 1)

vehicles$Wheelchair.Accessible<- ifelse(
  vehicles$Wheelchair.Accessible == "Y", 1, 0
)

vehicles.train = vehicles[lines, ]
vehicles.test = vehicles[-lines, ]

vehicles.glm = glm(Wheelchair.Accessible ~ Vehicle.Type, data = vehicles.train, 
                   family = binomial)
summary(vehicles.glm)

```
If type is Charter Sightseeing, Medicar  or Taxi, it has statistically significant effect on the y

```{r}
vehicles.glm = glm(Wheelchair.Accessible ~ Public.Vehicle.Number, data = vehicles.train, 
                   family = binomial)
summary(vehicles.glm)

```
Public.Vehicle.Number is considered statistically important, but it needs to be checked

```{r}
vehicles.glm = glm(Wheelchair.Accessible ~ Status, data = vehicles.train, 
                   family = binomial)
summary(vehicles.glm)

```
If status is FORECLOSURE, INACTIVE, RESERVED, SURRENDER, VIOLATION, it does have a significant effect on the y. 
Status of HOLD is considered moderately significant

```{r}
vehicles.glm = glm(Wheelchair.Accessible ~ Vehicle.Make, data = vehicles.train, 
                   family = binomial)
summary(vehicles.glm)

```
Vehicle.Make doesn't affect the Wheelchair Accessibility

```{r}
vehicles.glm = glm(Wheelchair.Accessible ~ Vehicle.Model, data = vehicles.train, 
                   family = binomial)
summary(vehicles.glm)

```
Vehicle.Model also doesn't affect the Wheelchair Accessibility

```{r}
vehicles.glm = glm(Wheelchair.Accessible ~ Vehicle.Model.Year, data = vehicles.train, 
                   family = binomial)
summary(vehicles.glm)
```
Wheelchair.Model.Year is statistically significant 

```{r}
vehicles.glm = glm(Wheelchair.Accessible ~ Vehicle.Color, data = vehicles.train, 
                   family = binomial)
summary(vehicles.glm)

```
Vehicle.Color is not statistically significant for y

```{r}
vehicles.glm = glm(Wheelchair.Accessible ~ Vehicle.Fuel.Source, data = vehicles.train, 
                   family = binomial)
summary(vehicles.glm)
```
Vehicle.Fuel.Source is also considered not important for the vehicle.  

For the following columns, training data set was too large, therefore, I decided to make a very little data subset just to check whether those predictors are significant or not. 

```{r}
vehicles.glm = glm(Wheelchair.Accessible ~ CompanyGroup, data = vehicles.train, 
                  family = binomial)
summary(vehicles.glm)
```
CompanyGroup is a significant predictor



```{r}

vehicles.glm = glm(Wheelchair.Accessible ~ AddressesGroup, data = vehicles.train, 
                   family = binomial)
summary(vehicles.glm)
```
AddressesGroup is also a significant predictor

```{r}
vehicles.glm = glm(Wheelchair.Accessible ~ City, data = vehicles.train, 
                   family = binomial)
summary(vehicles.glm)
```
City is not statistically significant

```{r}
vehicles.glm = glm(Wheelchair.Accessible ~ RecordsGroup, data = vehicles.train, 
                   family = binomial)
summary(vehicles.glm)
```
RecordsGroup also appears as statistically significant

```{r}
vehicles.glm = glm(Wheelchair.Accessible ~ ZIP.Code, data = vehicles.train, 
                   family = binomial)
summary(vehicles.glm)
```
ZIP code appears to be statistically significant. 

```{r}
vehicles.glm = glm(Wheelchair.Accessible ~ DatesGroup, data = vehicles.train, 
                   family = binomial)
summary(vehicles.glm)
```
DatesGroup also is statistically significant



Now, as we undesrtood statistically significant predictors, we can make a real model. 
```{r}
vehicles.glm = glm(Wheelchair.Accessible ~ Vehicle.Type + Status + Vehicle.Model.Year 
                   + Public.Vehicle.Number + ZIP.Code + AddressesGroup + CompanyGroup
                   + RecordsGroup + DatesGroup, data = vehicles.train, family = "binomial")

summary(vehicles.glm)
```
From this summary we can understand that Vehicle.Type, Status, Vehicle.Model.Year, Public.Vehicle.Numer, ZIP.Code and Groups variables are indeed statistically significant predictors. 

Now we need to see how accurately the model predicts the outcomes (whether the vehicle will be accessible or not)



```{r}
accessibility.train = vehicles.train$Wheelchair.Accessible
model.probs = predict(vehicles.glm, vehicles.train, type="response")

summary(model.probs)

model.preds = rep(0, 75960)
model.preds[model.probs > 0.5] = 1

table(model.preds, accessibility.train)
mean(model.preds == accessibility.train)

```
We can see that the model predicts the accessibility of places with a 96% accuracy on a training set. Let's see how's that going in a test set. 

```{r}
accessibility.test = vehicles.test$Wheelchair.Accessible
model.probs = predict(vehicles.glm, vehicles.test, type="response")

summary(model.probs)

model.preds = rep(0, 18988)
model.preds[model.probs > 0.5] = 1

table(model.preds, accessibility.test)
mean(model.preds == accessibility.test)
```
The accuracy of prediction on the test set is the same - 96%. It means that the model does really well to identify which vehicles will be accessible and which not.


Now we will plot graphs to visualize our data. 

```{r}

ggplot(data = vehicles) + 
  geom_point(mapping = aes(x = Wheelchair.Accessible, y = ModelYear_clean, color = Vehicle.Fuel.Source))
```


